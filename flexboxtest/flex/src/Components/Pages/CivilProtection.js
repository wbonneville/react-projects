import React, { Component } from "react";
import styled from "styled-components";

const Div = styled.div`
  font-size: 23px;
  margin-left: 7%;
  margin-right: 7%;
  margin-top: 4%;
  margin-bottom: 5%;

  & h4 {
    font-weight: 100;
    margin-top: -2%;
  }

  & .bigh1 {
    color: #ff6666;
    font-size: 22px;
    font-weight: 100;
  }
`;

export default class Housing extends Component {
  render() {
    return (
      <Div className="row start-xs">
        <div className="col-xs-10">
          <h1 className="bigh1">Messages from our Benefactors</h1>

          <h1>On Civil Protection</h1>

          <h4>September 16th, 2019</h4>
          <p>
            Some people think that artificial intelligence, particularly machine
            learning, has the potential to solve major problems such as
            unemployment, as well as to save lives, with health care, medical
            imaging, even traffic safety. Algorithms will spare us from a great
            many decisions that would otherwise have to be made. In addition,
            all sorts of things, from politics to social policy, will be made
            more efficient by artificial intelligence. But the downside of AI is
            even bigger: In addition to shrinking available jobs, AI will
            probably increase inequality in many countries, and enrich the
            already wealthy at the expense of the rest of us.
            <br></br>
            <br></br>
            It is a question, then, about whether certain types of AI will work
            well, whether they should work well, and how to prevent them from
            working well. One way to do that is to think about AI from the
            perspective of a great many people: the fully developed human mind.
            Let’s take a couple of cases. In the first case, there is a
            self-driving car. In the second case, there is a direct assault on
            the human brain, and probably other kinds of technology that make
            physical things too expensive to use for the same purpose. Based on
            the past century of experience with things like driverless cars,
            machines will learn more and more sophisticated functions. The
            brain, then, has a huge head start in knowing what types of tasks
            are valuable and what types are not, and in figuring out the best
            way to carry out those tasks — the well-suited, efficient way.
            <br></br>
            <br></br>
            The future of this industry is going to be determined by human
            competency. We can think about what we do well: It’s not work that
            we simply decide to do — it’s work that requires specific skills and
            abilities, like reading, like reading, like reading, like reading. A
            fully developed human mind, the type that the new generation of
            machines should be trying to emulate, can understand this
            relationship, and so may be able to tell the difference between
            expensive and cheap task types, and between tasks and things. In the
            case of self-driving cars, they could copy the intuitive and
            systematic structure of a fully developed human mind.
            <br></br>
            <br></br>
            But they might not, since, as they learn to perform tasks, they
            might develop error rates that are too high, or too low, for their
            purely robotic intelligence to pick up — perhaps in large part
            because of the nature of the tasks they are trying to do. This could
            have serious consequences. We might ask ourselves whether such a
            situation will be tolerable. Human beings, in many ways, and
            especially in terms of personal health care, have long lived with
            serious health problems, sometimes life-threatening ones. Could we
            live that way if we relied only on machines for everything? In some
            cases, we probably could, but it would be sad. There are, however,
            situations in which human competency is of less use to machines,
            because even the human brain is not absolutely flawless. For
            example, we can only identify trouble with the eye very well if we
            have good vision.
            <br></br>
            <br></br>
            There is a huge gulf between what robots can do and what the human
            mind can do, for any number of reasons. That leads to a second
            problem, which I’ll call “distortions.” In the world of science
            fiction, these can be deadly, often reducing whole populations to
            disaster. In other cases, they are more prosaic — like the use of AI
            by dictators to suppress political movements. I’m not really worried
            about the development of distorting devices. Distortions happen in
            any human or machine context, but at the moment only governments and
            journalists are interested in developing them, because that’s where
            their sources of data are. But it’s an open question whether there
            is as yet nothing terribly distorting about digital technologies.
            And once again, much of the world will be closely watching the US.
            <br></br>
            <br></br>
            The US is a major researcher and developer of AI — but we are not
            quite there yet, so we don’t have the experience of living with
            distortions. So when, some day, those distortions appear, they could
            show us how dangerous — or how useful — distorting technology can
            be. In other words, we need to be watchful, but there should be room
            for self-insurance too.
          </p>

          <h1>We've Been Given Tools</h1>
          <h4>September 16th, 2019</h4>
          <p>
            AI can automate conversations, detect emotions, recognize objects,
            target advertising, and adapt its use to changing conditions and
            situations. In 2021, it could replace part of the workforce, freeing
            up humans for other activities. Most important, many will predict
            the gradual inevitability of having machines do our jobs. Large and
            experienced data scientists, who tend to have senior management
            backing, will probably be early beneficiaries of AI-driven change.
            Then there will be farmers, salespeople, lawyers, analysts, and
            journalists who can use automation for routine tasks while
            outsourcing work that requires creativity. Likewise, many retail
            employees — it would appear even the supermarket cashier — will need
            a new role. At the current stage of development, scientists are not
            aware of the resulting effects on the labor markets. The goal is to
            stay ahead of them, or, at least, to keep a good sense of the
            situation. This kind of uncertainty about the consequences of
            algorithmic change is a hallmark of life in new technologies. The
            researchers and entrepreneurs involved are forced to make
            assumptions about whether they can influence the future state of AI
            at their level, and they have a fiduciary duty to tell it like it
            is.
            <br></br>
            <br></br>
            That’s an unusual situation in human enterprises. It’s now obvious
            to anyone who has ever followed emerging trends in human cultures
            that uprisings such as the French Revolution, the American
            Revolution, the Russian Revolution, the Russian Revolution, and the
            Chinese Revolution were not the result of information and technology
            that simply revealed previously undisclosed truths to the populace.
            <br></br>
            <br></br>
            Instead, massive upheaval resulted from people seeing that things
            had changed — and needed to change. This is what’s called “social
            unrest.” The Oxford Econometric Model (OEM) is a major and
            sophisticated (for now) scholarly research tool that most economists
            use to help make predictions about what will happen in the future.
            It arrives at the useful conclusion that within a decades,
            automation of routine jobs will make large numbers of workers move
            from the job market into unskilled service jobs — also, and
            unsurprisingly, far less desirable. It assumes that the workers in
            the service jobs have similar skills and that the economy will grow
            in these high-skilled “creative” occupations. It also indicates that
            with the ongoing expansion of robotics and AI, there is a distinct
            possibility that the labor market will become saturated with this
            new type of service occupation — essentially robot jobs.
          </p>
          <h1>AI and the Combine</h1>
          <h4>September 1st, 2019</h4>
          <p>
            I think those who say the Internet will take over all economic and
            governmental functions miss a crucial point. While City 17 has
            succeeded in creating software that’s more intelligent than humans,
            it’s not necessarily adapting to the age in which humans live. Human
            intelligence, at least our working intelligence, must include
            natural speech and body language, and while some programming and
            coding might have improved over time, what’s called the “human
            element” remains.
            <br></br>
            <br></br>
            That’s a part of the challenge the next wave of artificial
            intelligence will face. Because humans have no engine of choice to
            inform them of what’s going on, they rely on biases and gut instinct
            to guide their decision-making. Unfortunately, this leaves humanity
            vulnerable to woefully inaccurate decisions, indiscriminate bias,
            and silly decisions. So far, AI can’t replace the sensibility and
            intuition of human decision-makers — but some research suggests it
            can make less reasoned decisions, based on implicit bias and
            stereotypes that reflect human nature.
            <br></br>
            <br></br>
            In March 2018, three researchers, led by Micah Sifry, published
            research about systems in China that seemed to consistently endorse
            results that were inconsistent with what the participants had said.
            The study was a naturalistic experiment, meant to illustrate the
            problems inherent in artificial intelligence. If we cannot make
            intelligent systems that develop without bias, we can’t make
            intelligent systems that act in the public interest. We are racing
            toward a horizon of real AI technology that could have a dramatic
            impact on the world. AI has the power to revolutionize everything
            from the economy to society. The impact of AI could be like the IT
            revolution.
            <br></br>
            <br></br>
            Just as it revolutionized the economy by providing more efficient
            ways to run machines, so can it change government operations by
            providing more efficient ways to govern. The problem is, the time to
            get smart is before “humans are too dumb to use it.” It’s not about
            machines replacing humans. It’s about machines making better
            choices.
          </p>
        </div>
      </Div>
    );
  }
}
